============
DSLR Project
============

***********************
Логистическая регрессия
***********************

В методе логистической регрессии значением функции является вероятность того, что данное исходное значение принадлежит к определенному классу, т.е. результат логистической регрессии всегда находится в интервале
:math:`\Large{[0,1]}`.

Функция линейной регрессии задается формулой

.. math ::
    \Large{f(w,x_i) = \vec{w}^T \vec{x_i}\qquad\qquad\qquad\qquad\qquad (1)}

В двумерном случае уравнение линейной регрессии имеет вид:

.. math ::
    \Large{f(w,x_i) = w_0 + w_1x_{i1} + w_2x_{i2}\qquad\qquad (2)}

Прямая, определяемая уравнением :math:`{(2)}`, называется линейным дискриминантом, т.к.  она является линейной с точки зрения своей функции, и позволяет модели производить разделение, дискриминацию точек на различные классы.

Важно:

 :math:`\Large{x_1}` и :math:`\Large{x_2}`

являются исходными переменными, а выходная переменная не является частью исходного пространства в отличие от метода линейной регрессии.

Уравнение прямой делит плоскость на три части:

1. Если точка :math:`\Large{M(a,b)}` находится под прямой, относим ее к классу :math:`\Large{+}`.
Чем больше расстояние от функции :math:`\Large{f(w, x_i)}` до точки :math:`\Large{M(a,b)}`, тем выше вероятность :math:`\Large{p_+}`, что точка :math:`\Large{M(a,b)}` принадлежит классу :math:`\Large{+}`.
Вероятность принадлежности  точки :math:`\Large{M(a,b)}` классу :math:`\Large{+}` находится в диапазоне :math:`\Large{(0.5,1]}`.


2. Если точка :math:`\Large{M(a,b)}` находится над прямой, относим ее к классу :math:`\Large{-}`.

Чем больше расстояние от функции :math:`\Large{f(w, x_i)}` до точки :math:`\Large{M(a,b)}`, тем выше вероятность, что точка :math:`\Large{M(a,b)}` принадлежит классу :math:`\Large{-}`.

Вероятность :math:`\Large{p_+}` принадлежности  точки :math:`\Large{M(a,b)}`

классу :math:`\Large{-}` находится в диапазоне :math:`\Large{[0, 0.5)}`.


3. Если точка :math:`\Large{M(a,b)}` находится на прямой, относим ее к классу :math:`\Large{0}`.

Вероятность :math:`\Large{p_+}` принадлежности  точки :math:`\Large{M(a,b)}` классу :math:`\Large{0}` равно :math:`\Large{0.5}`


Преобразования функции линейной регрессии

.. math ::
    \Large{f(w,x_i) = \vec{w}^T \vec{x_i}}


в функцию логистического отклика

.. math ::
    \Large{\sigma(\vec{w}^T \vec{x_i}) = \frac{1}{1+e^{-\vec{w}^T \vec{x_i}}}}

или

:math:`\Large{(-\infty,+\infty)}` →  Шансы :math:`\Large{[0,+\infty)}`  → Вероятность :math:`\Large{[0,1]}`

Пусть

:math:`\Large{p(X)}` — вероятность наступления события :math:`\Large{X}`.

Значения :math:`\Large{p(X)}` лежат в диапазоне :math:`\Large{[0,1]}`.

Шансы :math:`\Large{odds(X)}` —  это вероятность наступления события :math:`\Large{X}`, деленная на вероятность того, что событие не произойдет.
Формула шанса наступления события:


.. math ::
    \Large{odds(X) = \frac{p(X)}{1-p(X)}},


где

:math:`\Large{p(X)}` — вероятность наступления события :math:`\Large{X}`,

:math:`\Large{1 - p(X)}` — вероятность НЕ наступления события :math:`\Large{X}`.

Значения :math:`\Large{odds(X)}` лежат в диапазоне :math:`\Large{[0,+\infty)}`.


Пример: Выражение ”Шансы 4 к 1”, эквивалентно отношению

.. math ::
    \Large{\frac{0.8}{0.2}}.

Выведем Обратную функцию шансов:

.. math ::
    \Large{p(X) = \frac{p(X)} {1-p(X) }:\frac{1}{1-p(X)} = \frac{p(X)} {1-p(X)}:\frac{1 - p(X) + p(X)}{1-p(X)}  = \frac{p(X)} {1-p(X)}:(1 + \frac{p(X)}{1-p(X)}) = \frac{odds(X)}{1+odds(X)}\qquad\qquad(3)}

Прологарифмировав шансы :math:`\Large{odds(X)}`, получим логарифм отношения шансов: :math:`\Large{log(odds(X))}`.

Значения :math:`\Large{log(odds(X))}` лежат в диапазоне :math:`\Large{(-\infty,+\infty)}`.

Таким образом, получен способ интерпретации результатов, подставленных в граничную функцию исходных значений. В используемой модели граничная функция определяет логарифм отношения шансов класса :math:`\Large{+}`.

.. math ::
    \Large{f(w,x_i)=\vec{w}^T\vec{x}=log(odds_+)}

Т.е. зная значение функции

.. math ::
    \Large{f(w,x_i)},

можно вычислить Шансы:

.. math ::
    \Large{odds(X) = e^{f(w,x_i)} = e^{\vec{w}^T\vec{x}}\qquad\qquad\qquad (4)}

Подставляя в :math:`\Large {(3)}`, получаем:

.. math ::
    \Large{p(X) = \frac{e^{\vec{w}^T\vec{x}}}{1+e^{\vec{w}^T\vec{x}}} = \frac{1}{1+e^{-\vec{w}^T\vec{x}}} = \sigma(\vec{w}^T\vec{x})}

Получили выражение вероятности наступления События через функцию логистического отклика или сигмоид-функцию.

**********************
Статистические метрики
**********************

count
-----
Количество значений параметра в выборке (исключая NaN значения)

mean
----
Среднее значение в выборке. Сумма значений, деленая на количество

std
---
Среднее  квадратическое  отклонение характеризует  среднее  отклонение
фактических  значений признака  в  статистической  совокупности от  их  среднего
значения.

Для генеральной совокупности:

.. math ::
    \sigma = \sqrt{\frac{\sum_{i=1}^{n}(x_{i} - \mu )^{2}}{n}}

Для выборки:

.. math ::
    s = \sqrt{\frac{\sum_{i=1}^{n}(x_{i} - \mu )^{2}}{n - 1}}

Среднее  квадратическое  отклонение  также  называют  стандартным
отклонением.
В  нормальном  распределении примерно  2/3  всех  значений  отклоняются  от
среднего  уровня  не  больше,  чем  на  одну  величину  среднего  квадратического
отклонения. Приблизительно 95% всех значений отклоняются от среднего уровня
не более чем на две величины среднего квадратического отклонения. И, наконец,
около  99,7%  всех  значений  лежат  в  пределах  трех  средних  квадратических
отклонений  (правило 3-х сигм)

percentile
----------
n-Процентиль - это показатель, используемый в статистике , указывающий значение, ниже которого падает данный процент наблюдений в группе наблюдений.
Например, 20-й процентиль - это значение (или балл), ниже которого могут быть обнаружены 20% наблюдений. Эквивалентно 80% наблюдений находятся выше 20-го процентиля.

Существуют различные методы расчета процентилей. В проекте используется метод линейной интерполяции.

min
---
Минимальное значение в выборке

max
---
Максимальное значение в выборке

variance
--------
В статистике дисперсией называют величину, которая характеризует меру разброса значений случайной величины относительно ее математического ожидания.
В русскоязычной литературе дисперсия обозначается D[X], а в англоязычной var(X) (от англ. variance — дисперсия).
Дисперсия представляет  собой  средний  квадрат  отклонений  значений
признака от средней величины.

Для генеральной совокупности:

.. math ::
    \sigma^{2} = {\frac{\sum_{i=1}^{n}(x_{i} - \mu )^{2}}{n}}

Для выборки:

.. math ::
    s^{2} = {\frac{\sum_{i=1}^{n}(x_{i} - \mu )^{2}}{n - 1}}

sum of squares
--------------
Сумма квадратов или сумма оценок квадратов отклонения равна ключевая мера изменчивости набора данных. Среднее значение суммы квадратов (SS) - это дисперсия набора оценок, а квадратный корень из дисперсии - это стандартное отклонение.
Для генеральной совокупности:

.. math ::
    SS = \sum_{i=1}^{n}(x_{i} - \mu )^{2}

Для выборки:

.. math ::
    SS = \sum_{i=1}^{n}(x_{i} -\bar{x} )^{2}

skewness
--------
Метрика для оценки ассиметричности распределения. Может быть положительной или отрицательной.

Асимметрия характеризует меру скошенности полигона или гистограммы влево / вправо относительно самого высокого участка
Отрицательная свидетельствует о том, что левый хвост распределения удлинен.
Положительная - правый хвост удлинен.
Нулевое значение метрики свидетельствует о полностью симметричном распределении

.. math ::
    \gamma _{1}= \frac{n}{(n-1)(n-2)}\sum_{i=1}^{n}(\frac{x_{i}- \bar{x}}{s})^{3}

kurtosis
--------
Позволяет сравнить хвосты распределения по сравнению с нормальным.
В работе используется формула Фишера-Пирсона (excess kurtosis) - из kurtosis вычитается значение для нормального распределения.

.. math ::
    G = \frac{(n+1)n}{(n-1)(n-2)(n-3)}\frac{\sum_{i=1}^{n}(x_{i} - \bar{x})^{4}}{k_{2}^{2}} - 3\frac{(n-1)^{2}}{(n-2)(n-3)}

где :math:`k_2` - среднее квадратичное отклонение

mode
----
Мода - наиболее часто встречающееся значение в выборке